# -*- coding: utf-8 -*-
"""LimerickFinder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15HktnmzrLKUPi22C3cyEAu7A5kmTqcJ0

# Preparation
"""

#pip install spacy
#first install the library that would help us use BERT in an easy to use interface
#https://github.com/UKPLab/sentence-transformers/tree/master/sentence_transformers
import sentence_transformers
#!pip install -U sentence-transformers

#import spacy
#from spacy.lang.en.stop_words import STOP_WORDS
#from string import punctuation
from collections import Counter
from heapq import nlargest

#ENABLE THIS IF THERE ARE PROBLEMS
#!python -m spacy download en_core_web_sm

"""# Add the data




"""

#pwd
import pandas as pd
df = pd.read_csv("limericks.csv")
#SOURCE:
#Almas Abdibayev, Allen Riddell, Yohei Igarashi, & Daniel Rockmore. (2021). Dataset of limericks for computational poetics (Version v3) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.5722527

#df.head

"""#Cleaning and Modeling"""

from sentence_transformers import SentenceTransformer
import scipy.spatial

embedder = SentenceTransformer('all-MiniLM-L6-v2')
#embedder = SentenceTransformer('bert-base-nli-mean-tokens')

#df.head()

df=df.drop_duplicates()

import re #for regular expressions
df['limerick'] = df['limerick'].apply(lambda x: re.sub('[^a-zA-z0-9\s]','',x)) #get rid of non alphanumerics

#put limericks in lower case
def lower_case(input_str):
    input_str = input_str.lower()
    return input_str

df['limerick']= df['limerick'].apply(lambda x: lower_case(x))

df_sentences = df.set_index('limerick')
df_sentences = df_sentences['id'].to_dict()
df_sentences_list = list(df_sentences.keys())

#list(df_sentences.keys())[:5]

import pandas as pd
from tqdm import tqdm
from sentence_transformers import SentenceTransformer, util

df_sentences_list = [str(d) for d in tqdm(df_sentences_list)]

# Corpus with example sentences
#!pwd
import pickle as pkl
corpus = df_sentences_list
infile = open("corpus_embeddings.pkl",'rb')
corpus_embeddings = pkl.load(infile)
infile.close()
#corpus_embeddings = embedder.encode(corpus,show_progress_bar=True)

#import pickle as pkl
#with open("corpus_embeddings.pkl" , "wb") as file_:
#  pkl.dump(corpus_embeddings,file_)

#query_embeddings.shape

import torch

# Query sentences:
queries = input('What kind of limerick would you like to find? ')
queries = [queries]
# Find the closest 5 limericks of the corpus for each query sentence based on cosine similarity
top_k = min(5, len(corpus))
for query in queries:
    query_embedding = embedder.encode(query, convert_to_tensor=True)

    # We use cosine-similarity and torch.topk to find the highest 5 scores
    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]
    top_results = torch.topk(cos_scores, k=top_k)

    print("\n\n======================\n\n")
    print("Query:", queries)
    print("\nTop relevant limericks:")

    for score, idx in zip(top_results[0], top_results[1]):
        print("(Score: {:.4f})".format(score))
        print(corpus[idx])
        
        row1_limerick = df.loc[df['limerick']== corpus[idx], 'line_1']
        row2_limerick = df.loc[df['limerick']== corpus[idx], 'line_2']
        row3_limerick = df.loc[df['limerick']== corpus[idx], 'line_3']
        row4_limerick = df.loc[df['limerick']== corpus[idx], 'line_4']
        row5_limerick = df.loc[df['limerick']== corpus[idx], 'line_5']
        print(row1_limerick,"\n")
        print(row2_limerick,"\n")
        print(row3_limerick,"\n")
        print(row4_limerick,"\n")
        print(row5_limerick,"\n")
        row_dict = df.loc[df['limerick']== corpus[idx]]
        print("poem_id:  " , row_dict['id'] , "\n")

#pip freeze > requirements.txt